{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "[dataset](https://www.cellpose.org/dataset) from cellpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import CellPoseModel\n",
    "from evaluate import average_precision\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "train_X, train_y = [], []\n",
    "test_X, test_y = [], []\n",
    "\n",
    "data_path = \"./dataset/train/\"\n",
    "list_data = sorted(os.listdir(data_path))\n",
    "\n",
    "print(\"Load train data\")\n",
    "for fpath in tqdm(list_data):\n",
    "    if \"img\" in fpath:\n",
    "        img = np.array(Image.open(os.path.join(data_path, fpath)).convert(\"L\"))\n",
    "        mask_fpath = fpath[:3] + \"_masks.png\"\n",
    "        mask = np.array(Image.open(os.path.join(data_path, mask_fpath)))\n",
    "\n",
    "        train_X.append(img)\n",
    "        train_y.append(mask)\n",
    "\n",
    "data_path = \"./dataset/test/\"\n",
    "list_data = sorted(os.listdir(data_path))\n",
    "\n",
    "print(\"Load test data\")\n",
    "for fpath in tqdm(list_data):\n",
    "    if \"img\" in fpath:\n",
    "        img = np.array(Image.open(os.path.join(data_path, fpath)).convert(\"L\"))\n",
    "        mask_fpath = fpath[:3] + \"_masks.png\"\n",
    "        mask = np.array(Image.open(os.path.join(data_path, mask_fpath)))\n",
    "\n",
    "        test_X.append(img)\n",
    "        test_y.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CellPoseModel(device=\"cuda\")\n",
    "print(\"Start Training\")\n",
    "model.train(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    test_X,\n",
    "    test_y,\n",
    "    n_epochs=5,\n",
    "    learning_rate=3e-4,\n",
    "    save_path=\"./\",\n",
    "    model_name=\"test\",\n",
    "    batch_size=2,\n",
    "    eval_batch_size=1,\n",
    "    save_every=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [model.predict(data, channels=[0,0], use_gpu=True)[0] for data in tqdm(test_X)]\n",
    "ap = average_precision(test_y, masks)\n",
    "print(ap[0][:, 0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import CellPoseModel\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def overlay(image, mask, alpha, resize=None):\n",
    "    \"\"\"Combines image and its segmentation mask into a single image.\n",
    "    https://www.kaggle.com/code/purplejester/showing-samples-with-segmentation-mask-overlay\n",
    "\n",
    "    Params:\n",
    "        image: Training image. np.ndarray,\n",
    "        mask: Segmentation mask. np.ndarray,\n",
    "        color: Color for segmentation mask rendering.  tuple[int, int, int] = (255, 0, 0)\n",
    "        alpha: Segmentation mask's transparency. float = 0.5,\n",
    "        resize: If provided, both image and its mask are resized before blending them together.\n",
    "\n",
    "    Returns:\n",
    "        image_combined: The combined image. np.ndarray\n",
    "\n",
    "    \"\"\"\n",
    "    color = list(np.random.choice(range(256), size=3))\n",
    "    colored_mask = np.expand_dims(mask, 0).repeat(3, axis=0)\n",
    "    colored_mask = np.moveaxis(colored_mask, 0, -1)\n",
    "    masked = np.ma.MaskedArray(image, mask=colored_mask, fill_value=color)\n",
    "    image_overlay = masked.filled()\n",
    "\n",
    "    if resize is not None:\n",
    "        image = cv2.resize(image.transpose(1, 2, 0), resize)\n",
    "        image_overlay = cv2.resize(image_overlay.transpose(1, 2, 0), resize)\n",
    "\n",
    "    image_combined = cv2.addWeighted(image, 1 - alpha, image_overlay, alpha, 0)\n",
    "\n",
    "    return image_combined\n",
    "\n",
    "model = CellPoseModel(pretrained_model='./models/model_ver1_epoch_100', device=\"cuda\")\n",
    "img = cv2.imread(\"./dataset/test/003_img.png\")\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(\"Start Predicting\")\n",
    "masks, flows, styles = model.predict(gray_img, channels=[0,0], use_gpu=True, resample=False, tile=True, batch_infer=9)\n",
    "img_overlay = overlay(np.array(img), masks, alpha=0.5)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_overlay)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
